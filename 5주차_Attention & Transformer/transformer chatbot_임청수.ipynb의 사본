{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5e8r1qIl0HKq","executionInfo":{"status":"ok","timestamp":1676518011163,"user_tz":-540,"elapsed":20085,"user":{"displayName":"임청수","userId":"15868859098317661860"}},"outputId":"31ac0bbb-916a-437c-932c-ddeb0f5cb52c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":47,"metadata":{"id":"qHER5WW80DnK","executionInfo":{"status":"ok","timestamp":1676513636043,"user_tz":-540,"elapsed":296,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["from collections import Counter\n","import json\n","import torch\n","import torch.nn as nn\n","\n","from torch.utils.data import Dataset\n","import torch.utils.data\n","import math\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"mP7EOrMp0Dnw","executionInfo":{"status":"ok","timestamp":1676513636369,"user_tz":-540,"elapsed":4,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["corpus_movie_conv = '/content/drive/MyDrive/2023-1 k=KUBIG NLP분반/movie_conversations.txt'\n","corpus_movie_lines = '/content/drive/MyDrive/2023-1 k=KUBIG NLP분반/movie_lines.txt'\n","max_len = 25"]},{"cell_type":"code","execution_count":49,"metadata":{"id":"rImcNnOi0Dnz","executionInfo":{"status":"ok","timestamp":1676513636711,"user_tz":-540,"elapsed":4,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["# Txt 파일 한줄씩 읽음\n","\n","with open(corpus_movie_conv, 'r') as c:\n","    conv = c.readlines()"]},{"cell_type":"code","execution_count":50,"metadata":{"id":"TRC7rEXb0Dn2","executionInfo":{"status":"ok","timestamp":1676513638312,"user_tz":-540,"elapsed":380,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["with open(corpus_movie_lines, 'r',encoding= 'unicode_escape') as l:\n","    lines = l.readlines()"]},{"cell_type":"code","execution_count":51,"metadata":{"id":"Z8Q2-kT_0Dn3","executionInfo":{"status":"ok","timestamp":1676513638312,"user_tz":-540,"elapsed":3,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["lines_dic = {}\n","for line in lines:\n","    objects = line.split(\" +++$+++ \") # txt파일 내의 구분자\n","\n","    lines_dic[objects[0]] = objects[-1] # index = 대사"]},{"cell_type":"code","execution_count":52,"metadata":{"id":"QCIifQ8f0Dn4","executionInfo":{"status":"ok","timestamp":1676513638712,"user_tz":-540,"elapsed":5,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["# 특수문자 제거\n","def remove_punc(string):\n","    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n","    no_punct = \"\"\n","    for char in string:\n","        if char not in punctuations:\n","            no_punct = no_punct + char  # space is also a character\n","    return no_punct.lower() #소문자 변환"]},{"cell_type":"code","execution_count":53,"metadata":{"id":"9wjZLob80Dn6","executionInfo":{"status":"ok","timestamp":1676513645478,"user_tz":-540,"elapsed":6474,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["pairs = []\n","for con in conv:\n","    ids = eval(con.split(\" +++$+++ \")[-1]) # 연속적인 대사 별 인덱스를 모은 리스트를 저장\n","    for i in range(len(ids)):\n","        qa_pairs = []\n","        \n","        if i==len(ids)-1:\n","            break\n","        \n","        first = remove_punc(lines_dic[ids[i]].strip())      \n","        second = remove_punc(lines_dic[ids[i+1]].strip())\n","        qa_pairs.append(first.split()[:max_len])\n","        qa_pairs.append(second.split()[:max_len])\n","        pairs.append(qa_pairs)"]},{"cell_type":"code","source":["print(pairs[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YngkGgabACrN","executionInfo":{"status":"ok","timestamp":1676513727502,"user_tz":-540,"elapsed":7,"user":{"displayName":"임청수","userId":"15868859098317661860"}},"outputId":"e33966c8-923f-4a65-aa4e-385bdbd5c942"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["[['can', 'we', 'make', 'this', 'quick', 'roxanne', 'korrine', 'and', 'andrew', 'barrett', 'are', 'having', 'an', 'incredibly', 'horrendous', 'public', 'break', 'up', 'on', 'the', 'quad', 'again'], ['well', 'i', 'thought', 'wed', 'start', 'with', 'pronunciation', 'if', 'thats', 'okay', 'with', 'you']]\n"]}]},{"cell_type":"code","source":["print(lines_dic['L200'])\n","print(lines_dic['L201'])\n","print(lines_dic['L202'])\n","print(lines_dic['L203'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tZzshZvM_c1y","executionInfo":{"status":"ok","timestamp":1676513533788,"user_tz":-540,"elapsed":292,"user":{"displayName":"임청수","userId":"15868859098317661860"}},"outputId":"585d0bde-5b89-4068-e385-ed0644b0fd53"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["No, no, it's my fault -- we didn't have a proper introduction ---\n","\n","Cameron.\n","\n","The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\n","\n","Seems like she could get a date easy enough...\n","\n"]}]},{"cell_type":"code","execution_count":57,"metadata":{"id":"3CE3IFqI0Dn8","executionInfo":{"status":"ok","timestamp":1676513799714,"user_tz":-540,"elapsed":1208,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["word_freq = Counter()\n","for pair in pairs:\n","    word_freq.update(pair[0])\n","    word_freq.update(pair[1])"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"-ZdkHo5T0Dn9","executionInfo":{"status":"ok","timestamp":1676510690310,"user_tz":-540,"elapsed":503,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["min_word_freq = 5 # 빈도수가 5 이상인 단어만 정수 인코딩 진행\n","words = [w for w in word_freq.keys() if word_freq[w] > min_word_freq]\n","word_map = {k: v + 1 for v, k in enumerate(words)} \n","word_map['<unk>'] = len(word_map) + 1  # 스페셜 토큰도 정수인코딩 진행\n","word_map['<start>'] = len(word_map) + 1\n","word_map['<end>'] = len(word_map) + 1\n","word_map['<pad>'] = 0"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CX22MirC0Dn_","executionInfo":{"status":"ok","timestamp":1676510694633,"user_tz":-540,"elapsed":313,"user":{"displayName":"임청수","userId":"15868859098317661860"}},"outputId":"47ffd391-ede0-4a20-97ad-13d7875b160d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total words are: 18243\n"]}],"source":["print(\"Total words are: {}\".format(len(word_map))) # 걸러진 후 단어 수  "]},{"cell_type":"code","execution_count":15,"metadata":{"id":"yBbQx1ki0DoA","executionInfo":{"status":"ok","timestamp":1676510696829,"user_tz":-540,"elapsed":3,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["# word_map을 json 형태로 작성\n","with open('WORDMAP_corpus.json', 'w') as j:\n","    json.dump(word_map, j)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"9nvupiLp0DoB","executionInfo":{"status":"ok","timestamp":1676510703912,"user_tz":-540,"elapsed":317,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["def encode_question(words, word_map): # max_len만큼 패딩 추가\n","    enc_c = [word_map.get(word, word_map['<unk>']) for word in words] + [word_map['<pad>']] * (max_len - len(words))\n","    return enc_c"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"8YM_meLt0DoC","executionInfo":{"status":"ok","timestamp":1676510719570,"user_tz":-540,"elapsed":358,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["def encode_reply(words, word_map):   # reply는 start, end 스페셜 토큰을 단어 앞뒤로 붙이고 남은 공간에 패딩 추가\n","    enc_c = [word_map['<start>']] + [word_map.get(word, word_map['<unk>']) for word in words] + \\\n","    [word_map['<end>']] + [word_map['<pad>']] * (max_len - len(words))\n","    return enc_c"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"6JbCb78K0DoD","executionInfo":{"status":"ok","timestamp":1676510726609,"user_tz":-540,"elapsed":4058,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["pairs_encoded = []\n","for pair in pairs:\n","    qus = encode_question(pair[0], word_map)\n","    ans = encode_reply(pair[1], word_map)\n","    pairs_encoded.append([qus, ans])"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"nqrOTpK50DoF","executionInfo":{"status":"ok","timestamp":1676510736730,"user_tz":-540,"elapsed":8217,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["# 정수인코딩이 마친 pairs_encoded를 json형태로 작성\n","with open('pairs_encoded.json', 'w') as p:\n","    json.dump(pairs_encoded, p)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"4q_BLrru0DoG","executionInfo":{"status":"ok","timestamp":1676510743619,"user_tz":-540,"elapsed":297,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["# rev_word_map = {v: k for k, v in word_map.items()}\n","# ' '.join([rev_word_map[v] for v in pairs_encoded[1][0]])"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"iAgAEst80DoH","executionInfo":{"status":"ok","timestamp":1676510746823,"user_tz":-540,"elapsed":7,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["class Dataset(Dataset):\n","\n","    def __init__(self):\n","        # 인스턴스 생성 시 json파일 로드\n","        self.pairs = json.load(open('pairs_encoded.json'))\n","        self.dataset_size = len(self.pairs)\n","        # 인스턴스[i] 활용 시 정수인코딩된 pairs에서 i번째 question, reply를 텐서형태로 변환 후 return\n","    def __getitem__(self, i):\n","        \n","        question = torch.LongTensor(self.pairs[i][0])\n","        reply = torch.LongTensor(self.pairs[i][1])\n","            \n","        return question, reply\n","\n","    def __len__(self):\n","        return self.dataset_size"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"PPTrSaTp0DoI","executionInfo":{"status":"ok","timestamp":1676510901821,"user_tz":-540,"elapsed":3854,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["train_loader = torch.utils.data.DataLoader(Dataset(),\n","                                           batch_size = 100, \n","                                           shuffle=True, \n","                                           pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HckH99na0DoJ"},"outputs":[],"source":["# question, reply = next(iter(train_loader))"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"6VAndWDz0DoK","executionInfo":{"status":"ok","timestamp":1676510909464,"user_tz":-540,"elapsed":310,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["def create_masks(question, reply_input, reply_target):\n","    \n","    def subsequent_mask(size):\n","        mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n","        return mask.unsqueeze(0)\n","    \n","    question_mask = question!=0\n","    question_mask = question_mask.to(device)\n","    question_mask = question_mask.unsqueeze(1).unsqueeze(1)         # (batch_size, 1, 1, max_words)\n","     \n","    reply_input_mask = reply_input!=0\n","    reply_input_mask = reply_input_mask.unsqueeze(1)  # (batch_size, 1, max_words)\n","    reply_input_mask = reply_input_mask & subsequent_mask(reply_input.size(-1)).type_as(reply_input_mask.data) \n","    reply_input_mask = reply_input_mask.unsqueeze(1) # (batch_size, 1, max_words, max_words)\n","    reply_target_mask = reply_target!=0              # (batch_size, max_words)\n","    \n","    return question_mask, reply_input_mask, reply_target_mask"]},{"cell_type":"code","execution_count":24,"metadata":{"id":"RXPhhUf30DoL","executionInfo":{"status":"ok","timestamp":1676510926726,"user_tz":-540,"elapsed":413,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["class Embeddings(nn.Module):\n","    \"\"\"\n","    Implements embeddings of the words and adds their positional encodings. \n","    \"\"\"\n","    def __init__(self, vocab_size, d_model, max_len = 50):\n","        super(Embeddings, self).__init__()\n","        self.d_model = d_model\n","        self.dropout = nn.Dropout(0.1)\n","        self.embed = nn.Embedding(vocab_size, d_model)\n","        self.pe = self.create_positinal_encoding(max_len, self.d_model)\n","        self.dropout = nn.Dropout(0.1)\n","        \n","    def create_positinal_encoding(self, max_len, d_model): # 위치에 따른 임베딩 진행 \n","        pe = torch.zeros(max_len, d_model).to(device)\n","        for pos in range(max_len):   # for each position of the word\n","            for i in range(0, d_model, 2):   # for each dimension of the each position   # 짝수는 sin 홀수는 cos 활용\n","                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/d_model)))\n","                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n","        pe = pe.unsqueeze(0)   # include the batch size\n","        return pe\n","        \n","    def forward(self, encoded_words):\n","        embedding = self.embed(encoded_words) * math.sqrt(self.d_model)\n","        embedding += self.pe[:, :embedding.size(1)]   # pe will automatically be expanded with the same batch size as encoded_words\n","        embedding = self.dropout(embedding)\n","        return embedding"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"bGaiDQ590DoQ","executionInfo":{"status":"ok","timestamp":1676511445257,"user_tz":-540,"elapsed":304,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["class MultiHeadAttention(nn.Module): # 한번의 어텐션보다 여러 개의 어텐션을 병렬로 사용하는 것이 효과적 -> 8개의 어텐션 사용\n","    \n","    def __init__(self, heads, d_model):\n","        \n","        super(MultiHeadAttention, self).__init__()\n","        assert d_model % heads == 0 # head는 어텐션 수를 의미함\n","        self.d_k = d_model // heads\n","        self.heads = heads\n","        self.dropout = nn.Dropout(0.1)\n","        self.query = nn.Linear(d_model, d_model)   # transformer is self attention. so query, key, value are d_model\n","        self.key = nn.Linear(d_model, d_model)\n","        self.value = nn.Linear(d_model, d_model)\n","        self.concat = nn.Linear(d_model, d_model)\n","        \n","    def forward(self, query, key, value, mask):\n","        \"\"\"\n","        query, key, value of shape: (batch_size, max_len, 512)\n","        mask of shape: (batch_size, 1, 1, max_words)\n","        \"\"\"\n","        # (batch_size, max_len, 512)\n","        query = self.query(query)\n","        key = self.key(key)        \n","        value = self.value(value)   \n","        \n","        # (batch_size, max_len, 512) --> (batch_size, max_len, h, d_k) --> (batch_size, h, max_len, d_k)\n","        query = query.view(query.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)   \n","        key = key.view(key.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n","        value = value.view(value.shape[0], -1, self.heads, self.d_k).permute(0, 2, 1, 3)  \n","        \n","\n","\n","        # (batch_size, h, max_len, d_k) matmul (batch_size, h, d_k, max_len) --> (batch_size, h, max_len, max_len)\n","        scores = torch.matmul(query, key.permute(0,1,3,2)) / math.sqrt(query.size(-1)) # scaled 한 후 query key의 dot product 진행\n","\n","\n","        # pad가 있으면 음수를 곱해 소프트맥스 결과로 0이 되도록 함\n","        scores = scores.masked_fill(mask == 0, -1e9)    # (batch_size, h, max_len, max_len)\n","        weights = F.softmax(scores, dim = -1)           # (batch_size, h, max_len, max_len)\n","        weights = self.dropout(weights)\n","        # (batch_size, h, max_len, max_len) matmul (batch_size, h, max_len, d_k) --> (batch_size, h, max_len, d_k)\n","        context = torch.matmul(weights, value)  # value와 dot product 진행\n","\n","\n","        # (batch_size, h, max_len, d_k) --> (batch_size, max_len, h, d_k) --> (batch_size, max_len, h * d_k)\n","        context = context.permute(0,2,1,3).contiguous().view(context.shape[0], -1, self.heads * self.d_k)\n","        # (batch_size, max_len, h * d_k)\n","        interacted = self.concat(context)\n","        return interacted "]},{"cell_type":"code","execution_count":26,"metadata":{"id":"HBOn7EG50DoR","executionInfo":{"status":"ok","timestamp":1676511445566,"user_tz":-540,"elapsed":2,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["class FeedForward(nn.Module):\n","\n","    def __init__(self, d_model, middle_dim = 2048):\n","        super(FeedForward, self).__init__()\n","        \n","        self.fc1 = nn.Linear(d_model, middle_dim)\n","        self.fc2 = nn.Linear(middle_dim, d_model)\n","        self.dropout = nn.Dropout(0.1)\n","\n","    def forward(self, x):\n","        out = F.relu(self.fc1(x))\n","        out = self.fc2(self.dropout(out))\n","        return out"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"JQywcP0P0DoS","executionInfo":{"status":"ok","timestamp":1676511446288,"user_tz":-540,"elapsed":5,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","\n","    def __init__(self, d_model, heads):\n","        super(EncoderLayer, self).__init__()\n","        self.layernorm = nn.LayerNorm(d_model)\n","        self.self_multihead = MultiHeadAttention(heads, d_model)\n","        self.feed_forward = FeedForward(d_model)\n","        self.dropout = nn.Dropout(0.1)\n","\n","    def forward(self, embeddings, mask):\n","        interacted = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, mask))\n","        interacted = self.layernorm(interacted + embeddings)  # 평균과 분산을 활용해 값을 정규화 진행\n","        feed_forward_out = self.dropout(self.feed_forward(interacted)) \n","        encoded = self.layernorm(feed_forward_out + interacted)  # input + output\n","        return encoded"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"_iRvM10c0DoS","executionInfo":{"status":"ok","timestamp":1676511451174,"user_tz":-540,"elapsed":412,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["class DecoderLayer(nn.Module):\n","    \n","    def __init__(self, d_model, heads):\n","        super(DecoderLayer, self).__init__()\n","        self.layernorm = nn.LayerNorm(d_model)\n","        self.self_multihead = MultiHeadAttention(heads, d_model)\n","        self.src_multihead = MultiHeadAttention(heads, d_model)\n","        self.feed_forward = FeedForward(d_model)\n","        self.dropout = nn.Dropout(0.1)\n","        \n","    def forward(self, embeddings, encoded, src_mask, target_mask):\n","        query = self.dropout(self.self_multihead(embeddings, embeddings, embeddings, target_mask))   # look ahead mask\n","        query = self.layernorm(query + embeddings)  # norm\n","        interacted = self.dropout(self.src_multihead(query, encoded, encoded, src_mask)) # self attention이 아니므로 query만 디코더, key value는 인코더 행렬 사용\n","        interacted = self.layernorm(interacted + query)   # add\n","        feed_forward_out = self.dropout(self.feed_forward(interacted))\n","        decoded = self.layernorm(feed_forward_out + interacted)\n","        return decoded"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"Axd16aJa0DoT","executionInfo":{"status":"ok","timestamp":1676511451473,"user_tz":-540,"elapsed":2,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["class Transformer(nn.Module):\n","    \n","    def __init__(self, d_model, heads, num_layers, word_map):\n","        super(Transformer, self).__init__()\n","        \n","        self.d_model = d_model\n","        self.vocab_size = len(word_map)\n","        self.embed = Embeddings(self.vocab_size, d_model)\n","        self.encoder = nn.ModuleList([EncoderLayer(d_model, heads) for _ in range(num_layers)])\n","        self.decoder = nn.ModuleList([DecoderLayer(d_model, heads) for _ in range(num_layers)])\n","        self.logit = nn.Linear(d_model, self.vocab_size)\n","        \n","    def encode(self, src_words, src_mask):\n","        src_embeddings = self.embed(src_words)\n","        for layer in self.encoder:\n","            src_embeddings = layer(src_embeddings, src_mask)\n","        return src_embeddings\n","    \n","    def decode(self, target_words, target_mask, src_embeddings, src_mask):\n","        tgt_embeddings = self.embed(target_words)\n","        for layer in self.decoder:\n","            tgt_embeddings = layer(tgt_embeddings, src_embeddings, src_mask, target_mask)\n","        return tgt_embeddings\n","        \n","    def forward(self, src_words, src_mask, target_words, target_mask):\n","        encoded = self.encode(src_words, src_mask)\n","        decoded = self.decode(target_words, target_mask, encoded, src_mask)\n","        out = F.log_softmax(self.logit(decoded), dim = 2)\n","        return out"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"4cg57sZO0DoU","executionInfo":{"status":"ok","timestamp":1676511456837,"user_tz":-540,"elapsed":289,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["class AdamWarmup:\n","    \n","    def __init__(self, model_size, warmup_steps, optimizer):\n","        \n","        self.model_size = model_size\n","        self.warmup_steps = warmup_steps\n","        self.optimizer = optimizer\n","        self.current_step = 0\n","        self.lr = 0\n","        \n","    def get_lr(self):\n","        return self.model_size ** (-0.5) * min(self.current_step ** (-0.5), self.current_step * self.warmup_steps ** (-1.5))\n","        \n","    def step(self):\n","        # Increment the number of steps each time we call the step function\n","        self.current_step += 1\n","        lr = self.get_lr()\n","        for param_group in self.optimizer.param_groups:\n","            param_group['lr'] = lr\n","        # update the learning rate\n","        self.lr = lr\n","        self.optimizer.step()       "]},{"cell_type":"code","execution_count":31,"metadata":{"id":"Ed4_72lh0DoU","executionInfo":{"status":"ok","timestamp":1676511457132,"user_tz":-540,"elapsed":4,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["class LossWithLS(nn.Module):\n","\n","    def __init__(self, size, smooth):\n","        super(LossWithLS, self).__init__()\n","        self.criterion = nn.KLDivLoss(size_average=False, reduce=False)\n","        self.confidence = 1.0 - smooth\n","        self.smooth = smooth\n","        self.size = size\n","        \n","    def forward(self, prediction, target, mask):\n","        \"\"\"\n","        prediction of shape: (batch_size, max_words, vocab_size)\n","        target and mask of shape: (batch_size, max_words)\n","        \"\"\"\n","        prediction = prediction.view(-1, prediction.size(-1))   # (batch_size * max_words, vocab_size)\n","        target = target.contiguous().view(-1)   # (batch_size * max_words)\n","        mask = mask.float()\n","        mask = mask.view(-1)       # (batch_size * max_words)\n","        labels = prediction.data.clone()\n","        labels.fill_(self.smooth / (self.size - 1))\n","        labels.scatter_(1, target.data.unsqueeze(1), self.confidence)\n","        loss = self.criterion(prediction, labels)    # (batch_size * max_words, vocab_size)\n","        loss = (loss.sum(1) * mask).sum() / mask.sum()\n","        return loss"]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4gLQkYGk0DoV","executionInfo":{"status":"ok","timestamp":1676511468881,"user_tz":-540,"elapsed":6095,"user":{"displayName":"임청수","userId":"15868859098317661860"}},"outputId":"7d59fb74-ae0d-400f-ec58-801c195f6b46"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n","  warnings.warn(warning.format(ret))\n"]}],"source":["d_model = 512 # 워드임베딩 차원\n","heads = 8 # 어텐션 수\n","num_layers = 3 # 인코더, 디코더 층 수\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","epochs = 2 #10\n","\n","with open('WORDMAP_corpus.json', 'r') as j:\n","    word_map = json.load(j)\n","    \n","transformer = Transformer(d_model = d_model, heads = heads, num_layers = num_layers, word_map = word_map)\n","transformer = transformer.to(device)\n","adam_optimizer = torch.optim.Adam(transformer.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)\n","transformer_optimizer = AdamWarmup(model_size = d_model, warmup_steps = 4000, optimizer = adam_optimizer)\n","criterion = LossWithLS(len(word_map), 0.1)"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"ONgb-xOU0DoW","executionInfo":{"status":"ok","timestamp":1676511471978,"user_tz":-540,"elapsed":318,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["def train(train_loader, transformer, criterion, epoch):\n","    \n","    transformer.train()\n","    sum_loss = 0\n","    count = 0\n","\n","    for i, (question, reply) in enumerate(train_loader):\n","        \n","        samples = question.shape[0]\n","\n","        # Move to device\n","        question = question.to(device)\n","        reply = reply.to(device)\n","\n","        # Prepare Target Data\n","        reply_input = reply[:, :-1]\n","        reply_target = reply[:, 1:]\n","\n","        # Create mask and add dimensions\n","        question_mask, reply_input_mask, reply_target_mask = create_masks(question, reply_input, reply_target)\n","\n","        # Get the transformer outputs\n","        out = transformer(question, question_mask, reply_input, reply_input_mask)  # 결과 도출\n","\n","        # Compute the loss\n","        loss = criterion(out, reply_target, reply_target_mask)   # loss 계산\n","        \n","        # Backprop\n","        transformer_optimizer.optimizer.zero_grad()\n","        loss.backward()\n","        transformer_optimizer.step()  \n","        \n","        sum_loss += loss.item() * samples\n","        count += samples\n","        \n","        if i % 100 == 0:\n","            print(\"Epoch [{}][{}/{}]\\tLoss: {:.3f}\".format(epoch, i, len(train_loader), sum_loss/count))"]},{"cell_type":"code","execution_count":34,"metadata":{"id":"ibw6huGX0DoW","executionInfo":{"status":"ok","timestamp":1676511477204,"user_tz":-540,"elapsed":483,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["def evaluate(transformer, question, question_mask, max_len, word_map):\n","    \"\"\"\n","    Performs Greedy Decoding with a batch size of 1\n","    \"\"\"\n","    rev_word_map = {v: k for k, v in word_map.items()}\n","    transformer.eval()\n","    start_token = word_map['<start>']\n","    encoded = transformer.encode(question, question_mask)\n","    words = torch.LongTensor([[start_token]]).to(device)\n","    \n","    for step in range(max_len - 1):\n","        size = words.shape[1]\n","        target_mask = torch.triu(torch.ones(size, size)).transpose(0, 1).type(dtype=torch.uint8)\n","        target_mask = target_mask.to(device).unsqueeze(0).unsqueeze(0)\n","        decoded = transformer.decode(words, target_mask, encoded, question_mask)\n","        predictions = transformer.logit(decoded[:, -1])\n","        _, next_word = torch.max(predictions, dim = 1)\n","        next_word = next_word.item()\n","        if next_word == word_map['<end>']:\n","            break\n","        words = torch.cat([words, torch.LongTensor([[next_word]]).to(device)], dim = 1)   # (1,step+2)\n","        \n","    # Construct Sentence\n","    if words.dim() == 2:\n","        words = words.squeeze(0)\n","        words = words.tolist()\n","        \n","    sen_idx = [w for w in words if w not in {word_map['<start>']}]\n","    sentence = ' '.join([rev_word_map[sen_idx[k]] for k in range(len(sen_idx))])\n","    \n","    return sentence"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORPeeVGb0DoX","executionInfo":{"status":"ok","timestamp":1676512314711,"user_tz":-540,"elapsed":837512,"user":{"displayName":"임청수","userId":"15868859098317661860"}},"outputId":"39953e43-9148-4d1b-a3bf-5d70cf74f848"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [0][0/2217]\tLoss: 8.693\n","Epoch [0][100/2217]\tLoss: 7.924\n","Epoch [0][200/2217]\tLoss: 7.219\n","Epoch [0][300/2217]\tLoss: 6.681\n","Epoch [0][400/2217]\tLoss: 6.322\n","Epoch [0][500/2217]\tLoss: 6.070\n","Epoch [0][600/2217]\tLoss: 5.881\n","Epoch [0][700/2217]\tLoss: 5.733\n","Epoch [0][800/2217]\tLoss: 5.613\n","Epoch [0][900/2217]\tLoss: 5.514\n","Epoch [0][1000/2217]\tLoss: 5.430\n","Epoch [0][1100/2217]\tLoss: 5.360\n","Epoch [0][1200/2217]\tLoss: 5.298\n","Epoch [0][1300/2217]\tLoss: 5.243\n","Epoch [0][1400/2217]\tLoss: 5.195\n","Epoch [0][1500/2217]\tLoss: 5.152\n","Epoch [0][1600/2217]\tLoss: 5.115\n","Epoch [0][1700/2217]\tLoss: 5.080\n","Epoch [0][1800/2217]\tLoss: 5.049\n","Epoch [0][1900/2217]\tLoss: 5.020\n","Epoch [0][2000/2217]\tLoss: 4.995\n","Epoch [0][2100/2217]\tLoss: 4.970\n","Epoch [0][2200/2217]\tLoss: 4.947\n","Epoch [1][0/2217]\tLoss: 4.521\n","Epoch [1][100/2217]\tLoss: 4.430\n","Epoch [1][200/2217]\tLoss: 4.427\n","Epoch [1][300/2217]\tLoss: 4.425\n","Epoch [1][400/2217]\tLoss: 4.421\n","Epoch [1][500/2217]\tLoss: 4.418\n","Epoch [1][600/2217]\tLoss: 4.416\n","Epoch [1][700/2217]\tLoss: 4.411\n","Epoch [1][800/2217]\tLoss: 4.410\n","Epoch [1][900/2217]\tLoss: 4.408\n","Epoch [1][1000/2217]\tLoss: 4.408\n","Epoch [1][1100/2217]\tLoss: 4.408\n","Epoch [1][1200/2217]\tLoss: 4.408\n","Epoch [1][1300/2217]\tLoss: 4.407\n","Epoch [1][1400/2217]\tLoss: 4.407\n","Epoch [1][1500/2217]\tLoss: 4.405\n","Epoch [1][1600/2217]\tLoss: 4.404\n","Epoch [1][1700/2217]\tLoss: 4.404\n","Epoch [1][1800/2217]\tLoss: 4.405\n","Epoch [1][1900/2217]\tLoss: 4.404\n","Epoch [1][2000/2217]\tLoss: 4.404\n","Epoch [1][2100/2217]\tLoss: 4.404\n","Epoch [1][2200/2217]\tLoss: 4.402\n"]}],"source":["for epoch in range(epochs):\n","    \n","    train(train_loader, transformer, criterion, epoch)\n","    \n","    state = {'epoch': epoch, 'transformer': transformer, 'transformer_optimizer': transformer_optimizer}\n","    torch.save(state, 'checkpoint_' + str(epoch) + '.pth.tar')"]},{"cell_type":"code","execution_count":36,"metadata":{"id":"x3039SjS0DoX","executionInfo":{"status":"ok","timestamp":1676512500961,"user_tz":-540,"elapsed":835,"user":{"displayName":"임청수","userId":"15868859098317661860"}}},"outputs":[],"source":["checkpoint = torch.load('/content/checkpoint_1.pth.tar')\n","transformer = checkpoint['transformer']"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8IzgpZa50DoX","executionInfo":{"status":"ok","timestamp":1676513567784,"user_tz":-540,"elapsed":11250,"user":{"displayName":"임청수","userId":"15868859098317661860"}},"outputId":"3528dd39-b8c9-4081-e90a-c9c40420dc83"},"outputs":[{"name":"stdout","output_type":"stream","text":["Question: No, no, it's my fault\n","Maximum Reply Length: 10\n","i dont know what i mean\n","Question: quit\n"]}],"source":["while(1):\n","    question = input(\"Question: \") \n","    if question == 'quit':\n","        break\n","    max_len = input(\"Maximum Reply Length: \")\n","    enc_qus = [word_map.get(word, word_map['<unk>']) for word in question.split()]\n","    question = torch.LongTensor(enc_qus).to(device).unsqueeze(0)\n","    question_mask = (question!=0).to(device).unsqueeze(1).unsqueeze(1)  \n","    sentence = evaluate(transformer, question, question_mask, int(max_len), word_map)\n","    print(sentence)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0U2wFg4P0DoY"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"provenance":[{"file_id":"10eifDEBvqhvglWmk1KO9zmg9w92fGNcI","timestamp":1676509862237}]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":0}